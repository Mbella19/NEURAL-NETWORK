{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Diagnostics\n",
    "\n",
    "This notebook validates multi-scale feature stability across different aggregated timeframes (M1/M5/M15/H1) and visualizes time-based session flags alongside market-regime labels. Run it after generating the aggregated datasets in `data/processed/timeframes/` and the normalized splits, then tweak calculator parameters as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from feature_engineering.pipeline import build_default_feature_pipeline, run_feature_pipeline\n",
    "\n",
    "DATA_PATHS = {\n",
    "    \"M1\": \"data/raw/EURUSD_M1_202306010000_202412302358.csv\",\n",
    "    \"M5\": \"data/processed/timeframes/EURUSD_M5.csv\",\n",
    "    \"M15\": \"data/processed/timeframes/EURUSD_M15.csv\",\n",
    "    \"H1\": \"data/processed/timeframes/EURUSD_H1.csv\",\n",
    "}\n",
    "\n",
    "def load_dataset(tf=\"M5\", n=5000):\n",
    "    path = DATA_PATHS[tf]\n",
    "    df = pd.read_csv(path)\n",
    "    if \"TIMESTAMP\" not in df.columns:\n",
    "        if \"END_TIME\" in df.columns:\n",
    "            df[\"TIMESTAMP\"] = pd.to_datetime(df[\"END_TIME\"], errors=\"coerce\")\n",
    "        else:\n",
    "            raise ValueError(\"Dataset missing TIMESTAMP/END_TIME columns\")\n",
    "    else:\n",
    "        df[\"TIMESTAMP\"] = pd.to_datetime(df[\"TIMESTAMP\"], errors=\"coerce\")\n",
    "    return df.head(n)\n",
    "\n",
    "pipeline = build_default_feature_pipeline()\n",
    "sample_df = load_dataset(\"M5\", n=2000)\n",
    "result = run_feature_pipeline(sample_df, pipeline=pipeline)\n",
    "feature_df = result.dataframe\n",
    "feature_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = {}\n",
    "for tf in (\"M1\", \"M5\", \"M15\", \"H1\"):\n",
    "    df = load_dataset(tf, n=2000)\n",
    "    res = run_feature_pipeline(df, pipeline=pipeline)\n",
    "    subset = res.dataframe[[\n",
    "        \"BOS_BULLISH\",\n",
    "        \"BOS_BEARISH\",\n",
    "        \"SR_SUPPORT_STRENGTH\",\n",
    "        \"SR_RESISTANCE_STRENGTH\",\n",
    "        \"VOLATILITY_REGIME\",\n",
    "    ]]\n",
    "    summary[tf] = subset.mean()\n",
    "\n",
    "pd.DataFrame(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = feature_df.tail(500)\n",
    "fig, ax1 = plt.subplots(figsize=(12, 5))\n",
    "ax1.plot(plot_df[\"TIMESTAMP\"], plot_df[\"CLOSE\"], label=\"Close\", color=\"black\")\n",
    "ax1.set_ylabel(\"Price\")\n",
    "ax1_twin = ax1.twinx()\n",
    "ax1_twin.plot(plot_df[\"TIMESTAMP\"], plot_df[\"VOLATILITY_REGIME\"], label=\"Volatility Regime\", color=\"tab:orange\", alpha=0.6)\n",
    "ax1_twin.plot(plot_df[\"TIMESTAMP\"], plot_df[\"SESSION_OVERLAP\"], label=\"Session Overlap\", color=\"tab:blue\", alpha=0.4)\n",
    "ax1_twin.set_ylabel(\"Indicator Value\")\n",
    "lines, labels = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax1_twin.get_legend_handles_labels()\n",
    "ax1.legend(lines + lines2, labels + labels2, loc=\"upper left\")\n",
    "ax1.set_title(\"Session Overlaps and Volatility Regimes\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
